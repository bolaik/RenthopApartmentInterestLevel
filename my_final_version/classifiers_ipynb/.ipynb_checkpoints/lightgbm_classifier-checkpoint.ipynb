{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM from Microsoft for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict, defaultdict\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import re, string, time\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom functions for loading and preprocessing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_freq_vects(docs, max_feature=None, percent=None, token_pattern=u'(?u)\\b\\w\\w+\\b'):\n",
    "    vect = CountVectorizer(token_pattern=token_pattern)\n",
    "    feat_sparse = vect.fit_transform(docs.values.astype('U'))\n",
    "    freq_table = list(zip(vect.get_feature_names(), np.asarray(feat_sparse.sum(axis=0)).ravel()))\n",
    "    freq_table = pd.DataFrame(freq_table, columns=['feature', 'count']).sort_values('count', ascending=False)\n",
    "    if not max_feature:\n",
    "        if percent:\n",
    "            max_feature = int(percent * len(vect.get_feature_names()))\n",
    "        else:\n",
    "            max_feature = len(vect.get_feature_names())\n",
    "    feat_df = pd.DataFrame(feat_sparse.todense(), columns=vect.get_feature_names())\n",
    "    names = list(freq_table.feature[:max_feature])\n",
    "    return feat_df[names]\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    print('Loading features files')\n",
    "    basic_feat = pd.read_json('../feat_input/basic_feat.json')\n",
    "    longtime_feat = pd.read_csv('../feat_input/longtime_feat.csv')\n",
    "    encoded_feat = pd.read_csv('../feat_input/feat_stats_encoding.csv')\n",
    "\n",
    "    # apply ordinal encoding to categorical feature\n",
    "    print('Ordinal encoding')\n",
    "    basic_feat.display_address = basic_feat.display_address.replace(r'\\r$', '', regex=True)\n",
    "    basic_feat.street_address = basic_feat.street_address.replace(r'\\r$', '', regex=True)\n",
    "    categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\"]\n",
    "    for f in categorical:\n",
    "        if basic_feat[f].dtype == 'object':\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(basic_feat[f].values))\n",
    "            basic_feat[f] = lbl.transform(list(basic_feat[f].values))\n",
    "\n",
    "    all_feat = basic_feat.merge(longtime_feat, on='listing_id')\n",
    "    all_feat = all_feat.merge(encoded_feat, on='listing_id')\n",
    "\n",
    "    print(\"Features document-term matrix\")\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    punct = string.punctuation\n",
    "    punct = re.sub(\"'|-\", \"\", punct)\n",
    "    pattern = r\"[0-9]|[{}]\".format(punct)\n",
    "    all_feat['features'] = all_feat['features'].apply(lambda x: [re.sub(pattern, \"\", y) for y in x])\n",
    "    all_feat['features'] = all_feat['features'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "    all_feat['features'] = all_feat['features'].apply(lambda x: ['_'.join(['feature'] + y.split()) for y in x])\n",
    "    all_feat['features'] = all_feat['features'].apply(lambda x: ' '.join(x))\n",
    "    vect_df = most_freq_vects(all_feat['features'], max_feature=100, token_pattern=r\"[^ ]+\")\n",
    "    \n",
    "    all_feat = pd.concat([all_feat, vect_df], axis=1)\n",
    "    train = all_feat[all_feat.interest_level != -1].copy()\n",
    "    test = all_feat[all_feat.interest_level == -1].copy()\n",
    "    y_train=train[\"interest_level\"]\n",
    "\n",
    "    x_train = train.drop([\"interest_level\",\"features\"],axis=1)\n",
    "    x_test = test.drop([\"interest_level\",\"features\"],axis=1)\n",
    "\n",
    "    return x_train, y_train, x_test, x_test.columns.values, x_test.listing_id\n",
    "\n",
    "\n",
    "def _preprocess(dtrain, dtest):\n",
    "    # replace np.inf to np.nan\n",
    "    dtrain = dtrain.replace([np.inf, -np.inf], np.nan)\n",
    "    dtest = dtest.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # impute np.nan\n",
    "    dtrain_col_mean = dtrain.mean(axis=0)\n",
    "    dtrain, dtest = dtrain.fillna(dtrain_col_mean), dtest.fillna(dtrain_col_mean)\n",
    "\n",
    "    # perform standardization\n",
    "    dtrain_col_mean, dtrain_col_std = dtrain.mean(axis=0), dtrain.std(axis=0)\n",
    "    dtrain, dtest = map(lambda x: (x - dtrain_col_mean) / dtrain_col_std, (dtrain, dtest))\n",
    "\n",
    "    return dtrain, dtest\n",
    "\n",
    "\n",
    "def _preprocess_log(dtrain, dtest):\n",
    "    # replace np.inf to np.nan\n",
    "    dtrain = dtrain.replace([np.inf, -np.inf], np.nan)\n",
    "    dtest = dtest.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # impute np.nan\n",
    "    dtrain_col_mean = dtrain.mean(axis=0)\n",
    "    dtrain, dtest = dtrain.fillna(dtrain_col_mean), dtest.fillna(dtrain_col_mean)\n",
    "\n",
    "    # log transform of min-zero columns\n",
    "    dtrain_col_min = dtrain.min(axis=0)\n",
    "    zero_min_index = dtrain_col_min[dtrain_col_min >= 0].index\n",
    "\n",
    "    dtrain[zero_min_index] = np.log10(dtrain[zero_min_index] + 1.0)\n",
    "    dtest[zero_min_index] = np.log10(dtest[zero_min_index] + 1.0)\n",
    "\n",
    "    # perform standardization\n",
    "    dtrain_col_mean, dtrain_col_std = dtrain.mean(axis=0), dtrain.std(axis=0)\n",
    "    dtrain, dtest = map(lambda x: (x - dtrain_col_mean) / dtrain_col_std, (dtrain, dtest))\n",
    "\n",
    "    return dtrain, dtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caculate performance using 5-fold cross-validation. Using built-in function `lgb.cv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lgb_cv(dtrain, n_iters=10000, early_stop_rounds=250):\n",
    "    print('Start lightGBM cross-validation')\n",
    "    params = {'boosting': 'gbdt',\n",
    "              'application': 'multiclass',\n",
    "              'learning_rate': 0.03,\n",
    "              'metric': 'multi_logloss',\n",
    "              'max_depth': 5,\n",
    "              'lambda_l2': 10,\n",
    "              'feature_fraction': 0.7,\n",
    "              'bagging_fraction': 0.7,\n",
    "              'bagging_freq': 0,\n",
    "              'num_threads': 4,\n",
    "              'num_class': 3,\n",
    "              }\n",
    "    bst = lgb.cv(params=params, \n",
    "                 train_set=dtrain,\n",
    "                 num_boost_round=n_iters,\n",
    "                 nfold=5,\n",
    "                 stratified=True,\n",
    "                 metrics=['multi_error', 'multi_logloss'],\n",
    "                 verbose_eval=50,\n",
    "                 early_stopping_rounds=early_stop_rounds,\n",
    "                 seed=816)\n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features files\n",
      "Ordinal encoding\n",
      "Features document-term matrix\n",
      "Start lightGBM cross-validation\n",
      "[50]\tcv_agg's multi_logloss: 0.670743 + 0.00369493\tcv_agg's multi_error: 0.257841 + 0.0029109\n",
      "[100]\tcv_agg's multi_logloss: 0.585834 + 0.00440668\tcv_agg's multi_error: 0.250283 + 0.00271402\n",
      "[150]\tcv_agg's multi_logloss: 0.558139 + 0.00528378\tcv_agg's multi_error: 0.245724 + 0.00340572\n",
      "[200]\tcv_agg's multi_logloss: 0.545208 + 0.00569631\tcv_agg's multi_error: 0.241084 + 0.00353598\n",
      "[250]\tcv_agg's multi_logloss: 0.536845 + 0.00613826\tcv_agg's multi_error: 0.237761 + 0.00371065\n",
      "[300]\tcv_agg's multi_logloss: 0.531038 + 0.00642768\tcv_agg's multi_error: 0.235897 + 0.00362262\n",
      "[350]\tcv_agg's multi_logloss: 0.526804 + 0.00661905\tcv_agg's multi_error: 0.23456 + 0.00374246\n",
      "[400]\tcv_agg's multi_logloss: 0.523813 + 0.00671971\tcv_agg's multi_error: 0.233526 + 0.00399136\n",
      "[450]\tcv_agg's multi_logloss: 0.521442 + 0.00676792\tcv_agg's multi_error: 0.232351 + 0.0037019\n",
      "[500]\tcv_agg's multi_logloss: 0.519334 + 0.00684183\tcv_agg's multi_error: 0.231095 + 0.0043446\n",
      "[550]\tcv_agg's multi_logloss: 0.517761 + 0.00690598\tcv_agg's multi_error: 0.230791 + 0.00432632\n",
      "[600]\tcv_agg's multi_logloss: 0.516299 + 0.00692801\tcv_agg's multi_error: 0.229575 + 0.00419013\n",
      "[650]\tcv_agg's multi_logloss: 0.515019 + 0.00700104\tcv_agg's multi_error: 0.228927 + 0.00442397\n",
      "[700]\tcv_agg's multi_logloss: 0.514042 + 0.00700146\tcv_agg's multi_error: 0.228805 + 0.00445041\n",
      "[750]\tcv_agg's multi_logloss: 0.513122 + 0.00691064\tcv_agg's multi_error: 0.22846 + 0.00462984\n",
      "[800]\tcv_agg's multi_logloss: 0.512402 + 0.00686886\tcv_agg's multi_error: 0.22765 + 0.00450797\n",
      "[850]\tcv_agg's multi_logloss: 0.511804 + 0.00687301\tcv_agg's multi_error: 0.228238 + 0.0046519\n",
      "[900]\tcv_agg's multi_logloss: 0.511256 + 0.00690237\tcv_agg's multi_error: 0.227589 + 0.00469954\n",
      "[950]\tcv_agg's multi_logloss: 0.51082 + 0.00687452\tcv_agg's multi_error: 0.22767 + 0.00460054\n",
      "[1000]\tcv_agg's multi_logloss: 0.510448 + 0.00688508\tcv_agg's multi_error: 0.227488 + 0.00410171\n",
      "[1050]\tcv_agg's multi_logloss: 0.510109 + 0.00682035\tcv_agg's multi_error: 0.227772 + 0.00441299\n",
      "[1100]\tcv_agg's multi_logloss: 0.50982 + 0.00679172\tcv_agg's multi_error: 0.227468 + 0.00423811\n",
      "[1150]\tcv_agg's multi_logloss: 0.509651 + 0.0068263\tcv_agg's multi_error: 0.227447 + 0.00420989\n",
      "[1200]\tcv_agg's multi_logloss: 0.509367 + 0.00690739\tcv_agg's multi_error: 0.22761 + 0.00427318\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, _, _ = load_data()\n",
    "dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "dtest = lgb.Dataset(X_test)\n",
    "\n",
    "# cross-validation and training\n",
    "lgb_cv_hist = lgb_cv(dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features files\n",
      "Ordinal encoding\n",
      "Features document-term matrix\n",
      "Start lightGBM cross-validation\n",
      "[50]\tcv_agg's multi_logloss: 0.670758 + 0.00379916\tcv_agg's multi_error: 0.257558 + 0.00327367\n",
      "[100]\tcv_agg's multi_logloss: 0.585866 + 0.0044336\tcv_agg's multi_error: 0.250365 + 0.00238552\n",
      "[150]\tcv_agg's multi_logloss: 0.55819 + 0.00509038\tcv_agg's multi_error: 0.245015 + 0.00371422\n",
      "[200]\tcv_agg's multi_logloss: 0.545114 + 0.00556057\tcv_agg's multi_error: 0.240983 + 0.00397213\n",
      "[250]\tcv_agg's multi_logloss: 0.536811 + 0.00600708\tcv_agg's multi_error: 0.23764 + 0.00371976\n",
      "[300]\tcv_agg's multi_logloss: 0.530873 + 0.00631041\tcv_agg's multi_error: 0.23616 + 0.0040185\n",
      "[350]\tcv_agg's multi_logloss: 0.526661 + 0.00654293\tcv_agg's multi_error: 0.233567 + 0.00394095\n",
      "[400]\tcv_agg's multi_logloss: 0.523654 + 0.006598\tcv_agg's multi_error: 0.232695 + 0.00421412\n",
      "[450]\tcv_agg's multi_logloss: 0.521304 + 0.00657527\tcv_agg's multi_error: 0.231865 + 0.00371565\n",
      "[500]\tcv_agg's multi_logloss: 0.519348 + 0.00665249\tcv_agg's multi_error: 0.231156 + 0.00327135\n",
      "[550]\tcv_agg's multi_logloss: 0.51773 + 0.00656831\tcv_agg's multi_error: 0.23071 + 0.00330222\n",
      "[600]\tcv_agg's multi_logloss: 0.516262 + 0.00653917\tcv_agg's multi_error: 0.230345 + 0.00358187\n",
      "[650]\tcv_agg's multi_logloss: 0.515067 + 0.00657897\tcv_agg's multi_error: 0.229271 + 0.00410386\n",
      "[700]\tcv_agg's multi_logloss: 0.51409 + 0.00661058\tcv_agg's multi_error: 0.229372 + 0.00454032\n",
      "[750]\tcv_agg's multi_logloss: 0.513151 + 0.00661366\tcv_agg's multi_error: 0.228765 + 0.00401679\n",
      "[800]\tcv_agg's multi_logloss: 0.512395 + 0.00659764\tcv_agg's multi_error: 0.228359 + 0.00407162\n",
      "[850]\tcv_agg's multi_logloss: 0.511739 + 0.00668537\tcv_agg's multi_error: 0.228319 + 0.0041316\n",
      "[900]\tcv_agg's multi_logloss: 0.511049 + 0.00670339\tcv_agg's multi_error: 0.227934 + 0.00405103\n",
      "[950]\tcv_agg's multi_logloss: 0.510592 + 0.00674278\tcv_agg's multi_error: 0.227792 + 0.00406138\n",
      "[1000]\tcv_agg's multi_logloss: 0.510156 + 0.00680778\tcv_agg's multi_error: 0.227508 + 0.0041049\n",
      "[1050]\tcv_agg's multi_logloss: 0.509765 + 0.00680655\tcv_agg's multi_error: 0.227569 + 0.00439148\n",
      "[1100]\tcv_agg's multi_logloss: 0.509543 + 0.00682119\tcv_agg's multi_error: 0.227711 + 0.00421621\n",
      "[1150]\tcv_agg's multi_logloss: 0.509299 + 0.00688061\tcv_agg's multi_error: 0.22767 + 0.00437975\n",
      "[1200]\tcv_agg's multi_logloss: 0.509045 + 0.00693414\tcv_agg's multi_error: 0.227366 + 0.00458877\n",
      "[1250]\tcv_agg's multi_logloss: 0.508802 + 0.0069819\tcv_agg's multi_error: 0.227387 + 0.00499147\n",
      "[1300]\tcv_agg's multi_logloss: 0.508595 + 0.00700321\tcv_agg's multi_error: 0.226961 + 0.00509578\n",
      "[1350]\tcv_agg's multi_logloss: 0.508438 + 0.00701864\tcv_agg's multi_error: 0.226921 + 0.00512255\n",
      "[1400]\tcv_agg's multi_logloss: 0.508279 + 0.00700998\tcv_agg's multi_error: 0.227245 + 0.00519802\n",
      "[1450]\tcv_agg's multi_logloss: 0.508192 + 0.00698215\tcv_agg's multi_error: 0.227306 + 0.00499168\n",
      "[1500]\tcv_agg's multi_logloss: 0.508106 + 0.00702789\tcv_agg's multi_error: 0.226941 + 0.00488282\n",
      "[1550]\tcv_agg's multi_logloss: 0.508028 + 0.00703767\tcv_agg's multi_error: 0.226799 + 0.0053596\n",
      "[1600]\tcv_agg's multi_logloss: 0.508004 + 0.00702987\tcv_agg's multi_error: 0.226617 + 0.00548054\n",
      "[1650]\tcv_agg's multi_logloss: 0.508072 + 0.00708715\tcv_agg's multi_error: 0.226637 + 0.00530073\n",
      "[1700]\tcv_agg's multi_logloss: 0.508167 + 0.00714119\tcv_agg's multi_error: 0.226313 + 0.00478069\n",
      "[1750]\tcv_agg's multi_logloss: 0.50825 + 0.0071237\tcv_agg's multi_error: 0.226029 + 0.00470457\n",
      "[1800]\tcv_agg's multi_logloss: 0.508269 + 0.00711254\tcv_agg's multi_error: 0.226333 + 0.00476769\n",
      "[1850]\tcv_agg's multi_logloss: 0.508313 + 0.00712805\tcv_agg's multi_error: 0.22609 + 0.00439845\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, _, _ = load_data()\n",
    "X_train, X_test = _preprocess(X_train, X_test)\n",
    "dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "dtest = lgb.Dataset(X_test)\n",
    "\n",
    "# cross-validation and training\n",
    "lgb_cv_hist = lgb_cv(dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features files\n",
      "Ordinal encoding\n",
      "Features document-term matrix\n",
      "Start lightGBM cross-validation\n",
      "[50]\tcv_agg's multi_logloss: 0.670822 + 0.00382203\tcv_agg's multi_error: 0.257355 + 0.00337708\n",
      "[100]\tcv_agg's multi_logloss: 0.585802 + 0.00450364\tcv_agg's multi_error: 0.250121 + 0.00274774\n",
      "[150]\tcv_agg's multi_logloss: 0.558062 + 0.00512368\tcv_agg's multi_error: 0.245056 + 0.00324044\n",
      "[200]\tcv_agg's multi_logloss: 0.544917 + 0.00560101\tcv_agg's multi_error: 0.240942 + 0.00378651\n",
      "[250]\tcv_agg's multi_logloss: 0.536637 + 0.00604004\tcv_agg's multi_error: 0.237822 + 0.00394783\n",
      "[300]\tcv_agg's multi_logloss: 0.530764 + 0.00644503\tcv_agg's multi_error: 0.235877 + 0.00396739\n",
      "[350]\tcv_agg's multi_logloss: 0.526624 + 0.00664894\tcv_agg's multi_error: 0.234316 + 0.00429234\n",
      "[400]\tcv_agg's multi_logloss: 0.523617 + 0.0067692\tcv_agg's multi_error: 0.23306 + 0.00399839\n",
      "[450]\tcv_agg's multi_logloss: 0.521325 + 0.00674561\tcv_agg's multi_error: 0.232027 + 0.00432905\n",
      "[500]\tcv_agg's multi_logloss: 0.519328 + 0.00680089\tcv_agg's multi_error: 0.230831 + 0.0037477\n",
      "[550]\tcv_agg's multi_logloss: 0.517674 + 0.00681172\tcv_agg's multi_error: 0.23073 + 0.0032397\n",
      "[600]\tcv_agg's multi_logloss: 0.516234 + 0.00685649\tcv_agg's multi_error: 0.22992 + 0.00317706\n",
      "[650]\tcv_agg's multi_logloss: 0.515019 + 0.00679295\tcv_agg's multi_error: 0.229656 + 0.0032289\n",
      "[700]\tcv_agg's multi_logloss: 0.514023 + 0.00679603\tcv_agg's multi_error: 0.229413 + 0.00346965\n",
      "[750]\tcv_agg's multi_logloss: 0.513134 + 0.00679957\tcv_agg's multi_error: 0.229231 + 0.00387732\n",
      "[800]\tcv_agg's multi_logloss: 0.512391 + 0.00679969\tcv_agg's multi_error: 0.228846 + 0.00415277\n",
      "[850]\tcv_agg's multi_logloss: 0.511765 + 0.00680928\tcv_agg's multi_error: 0.228927 + 0.00433147\n",
      "[900]\tcv_agg's multi_logloss: 0.511204 + 0.00685997\tcv_agg's multi_error: 0.228704 + 0.00420715\n",
      "[950]\tcv_agg's multi_logloss: 0.510749 + 0.00690129\tcv_agg's multi_error: 0.22844 + 0.00432179\n",
      "[1000]\tcv_agg's multi_logloss: 0.510262 + 0.0069544\tcv_agg's multi_error: 0.228116 + 0.0043606\n",
      "[1050]\tcv_agg's multi_logloss: 0.509866 + 0.0070312\tcv_agg's multi_error: 0.228055 + 0.00426182\n",
      "[1100]\tcv_agg's multi_logloss: 0.509559 + 0.00702334\tcv_agg's multi_error: 0.228217 + 0.00425159\n",
      "[1150]\tcv_agg's multi_logloss: 0.509358 + 0.00700818\tcv_agg's multi_error: 0.22765 + 0.00419709\n",
      "[1200]\tcv_agg's multi_logloss: 0.509163 + 0.0070885\tcv_agg's multi_error: 0.227792 + 0.00435345\n",
      "[1250]\tcv_agg's multi_logloss: 0.508967 + 0.00714555\tcv_agg's multi_error: 0.227265 + 0.00487568\n",
      "[1300]\tcv_agg's multi_logloss: 0.508781 + 0.00725038\tcv_agg's multi_error: 0.227306 + 0.00488056\n",
      "[1350]\tcv_agg's multi_logloss: 0.50864 + 0.00727603\tcv_agg's multi_error: 0.227164 + 0.00452032\n",
      "[1400]\tcv_agg's multi_logloss: 0.508552 + 0.00731944\tcv_agg's multi_error: 0.227488 + 0.00455919\n",
      "[1450]\tcv_agg's multi_logloss: 0.508459 + 0.0073055\tcv_agg's multi_error: 0.227063 + 0.00451681\n",
      "[1500]\tcv_agg's multi_logloss: 0.508462 + 0.00736169\tcv_agg's multi_error: 0.227002 + 0.00463169\n",
      "[1550]\tcv_agg's multi_logloss: 0.508377 + 0.00740527\tcv_agg's multi_error: 0.22688 + 0.00482038\n",
      "[1600]\tcv_agg's multi_logloss: 0.50837 + 0.00738157\tcv_agg's multi_error: 0.226596 + 0.00501047\n",
      "[1650]\tcv_agg's multi_logloss: 0.508303 + 0.00740225\tcv_agg's multi_error: 0.226799 + 0.0045843\n",
      "[1700]\tcv_agg's multi_logloss: 0.508382 + 0.00740604\tcv_agg's multi_error: 0.226921 + 0.0044847\n",
      "[1750]\tcv_agg's multi_logloss: 0.508415 + 0.00745175\tcv_agg's multi_error: 0.226718 + 0.00470119\n",
      "[1800]\tcv_agg's multi_logloss: 0.508461 + 0.00745696\tcv_agg's multi_error: 0.226313 + 0.00457719\n",
      "[1850]\tcv_agg's multi_logloss: 0.508523 + 0.00747063\tcv_agg's multi_error: 0.226313 + 0.00447087\n",
      "[1900]\tcv_agg's multi_logloss: 0.508616 + 0.00747607\tcv_agg's multi_error: 0.226414 + 0.00419415\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, _, _ = load_data()\n",
    "X_train, X_test = _preprocess_log(X_train, X_test)\n",
    "dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "dtest = lgb.Dataset(X_test)\n",
    "\n",
    "# cross-validation and training\n",
    "lgb_cv_hist = lgb_cv(dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
