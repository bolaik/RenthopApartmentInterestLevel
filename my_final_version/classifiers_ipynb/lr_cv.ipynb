{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict, defaultdict\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import re, string, time\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom functions for loading and preprocessing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_freq_vects(docs, max_feature=None, percent=None, token_pattern=u'(?u)\\b\\w\\w+\\b'):\n",
    "    vect = CountVectorizer(token_pattern=token_pattern)\n",
    "    feat_sparse = vect.fit_transform(docs.values.astype('U'))\n",
    "    freq_table = list(zip(vect.get_feature_names(), np.asarray(feat_sparse.sum(axis=0)).ravel()))\n",
    "    freq_table = pd.DataFrame(freq_table, columns=['feature', 'count']).sort_values('count', ascending=False)\n",
    "    if not max_feature:\n",
    "        if percent:\n",
    "            max_feature = int(percent * len(vect.get_feature_names()))\n",
    "        else:\n",
    "            max_feature = len(vect.get_feature_names())\n",
    "    feat_df = pd.DataFrame(feat_sparse.todense(), columns=vect.get_feature_names())\n",
    "    names = list(freq_table.feature[:max_feature])\n",
    "    return feat_df[names]\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    print('Loading features files')\n",
    "    basic_feat = pd.read_json('../feat_input/basic_feat.json')\n",
    "    longtime_feat = pd.read_csv('../feat_input/longtime_feat.csv')\n",
    "    encoded_feat = pd.read_csv('../feat_input/feat_stats_encoding.csv')\n",
    "\n",
    "    # apply ordinal encoding to categorical feature\n",
    "    print('Ordinal encoding')\n",
    "    basic_feat.display_address = basic_feat.display_address.replace(r'\\r$', '', regex=True)\n",
    "    basic_feat.street_address = basic_feat.street_address.replace(r'\\r$', '', regex=True)\n",
    "    categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\"]\n",
    "    for f in categorical:\n",
    "        if basic_feat[f].dtype == 'object':\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(basic_feat[f].values))\n",
    "            basic_feat[f] = lbl.transform(list(basic_feat[f].values))\n",
    "\n",
    "    all_feat = basic_feat.merge(longtime_feat, on='listing_id')\n",
    "    all_feat = all_feat.merge(encoded_feat, on='listing_id')\n",
    "\n",
    "    print(\"Features document-term matrix\")\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    punct = string.punctuation\n",
    "    punct = re.sub(\"'|-\", \"\", punct)\n",
    "    pattern = r\"[0-9]|[{}]\".format(punct)\n",
    "    all_feat['features'] = all_feat['features'].apply(lambda x: [re.sub(pattern, \"\", y) for y in x])\n",
    "    all_feat['features'] = all_feat['features'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "    all_feat['features'] = all_feat['features'].apply(lambda x: ['_'.join(['feature'] + y.split()) for y in x])\n",
    "    all_feat['features'] = all_feat['features'].apply(lambda x: ' '.join(x))\n",
    "    vect_df = most_freq_vects(all_feat['features'], max_feature=100, token_pattern=r\"[^ ]+\")\n",
    "    \n",
    "    all_feat = pd.concat([all_feat, vect_df], axis=1)\n",
    "    train = all_feat[all_feat.interest_level != -1].copy()\n",
    "    test = all_feat[all_feat.interest_level == -1].copy()\n",
    "    y_train=train[\"interest_level\"]\n",
    "\n",
    "    x_train = train.drop([\"interest_level\",\"features\"],axis=1)\n",
    "    x_test = test.drop([\"interest_level\",\"features\"],axis=1)\n",
    "\n",
    "    return x_train, y_train, x_test, x_test.columns.values, x_test.listing_id\n",
    "\n",
    "\n",
    "def _preprocess(dtrain, dtest):\n",
    "    # replace np.inf to np.nan\n",
    "    dtrain = dtrain.replace([np.inf, -np.inf], np.nan)\n",
    "    dtest = dtest.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # impute np.nan\n",
    "    dtrain_col_mean = dtrain.mean(axis=0)\n",
    "    dtrain, dtest = dtrain.fillna(dtrain_col_mean), dtest.fillna(dtrain_col_mean)\n",
    "\n",
    "    # perform standardization\n",
    "    dtrain_col_mean, dtrain_col_std = dtrain.mean(axis=0), dtrain.std(axis=0)\n",
    "    dtrain, dtest = map(lambda x: (x - dtrain_col_mean) / dtrain_col_std, (dtrain, dtest))\n",
    "\n",
    "    return dtrain, dtest\n",
    "\n",
    "\n",
    "def _preprocess_log(dtrain, dtest):\n",
    "    # replace np.inf to np.nan\n",
    "    dtrain = dtrain.replace([np.inf, -np.inf], np.nan)\n",
    "    dtest = dtest.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # impute np.nan\n",
    "    dtrain_col_mean = dtrain.mean(axis=0)\n",
    "    dtrain, dtest = dtrain.fillna(dtrain_col_mean), dtest.fillna(dtrain_col_mean)\n",
    "\n",
    "    # log transform of min-zero columns\n",
    "    dtrain_col_min = dtrain.min(axis=0)\n",
    "    zero_min_index = dtrain_col_min[dtrain_col_min >= 0].index\n",
    "\n",
    "    dtrain[zero_min_index] = np.log10(dtrain[zero_min_index] + 1.0)\n",
    "    dtest[zero_min_index] = np.log10(dtest[zero_min_index] + 1.0)\n",
    "\n",
    "    # perform standardization\n",
    "    dtrain_col_mean, dtrain_col_std = dtrain.mean(axis=0), dtrain.std(axis=0)\n",
    "    dtrain, dtest = map(lambda x: (x - dtrain_col_mean) / dtrain_col_std, (dtrain, dtest))\n",
    "\n",
    "    return dtrain, dtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use sklearn built-in function `LogisticRegressionCV` to search for best parameter `C`, which gives the best prediction performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lr2cv(preprocess='linear'):\n",
    "    X_train, y_train_cls, X_test, _, _ = load_data()\n",
    "    if preprocess=='log':\n",
    "        X_train, X_test = _preprocess_log(X_train, X_test)\n",
    "    else:\n",
    "        X_train, X_test = _preprocess(X_train, X_test)\n",
    "\n",
    "    lrcv = LogisticRegressionCV()\n",
    "    params = {'Cs': [0.1, 1, 10],\n",
    "              'cv': 5,\n",
    "              'solver': 'liblinear',\n",
    "              'n_jobs': -1,\n",
    "              'verbose': 1,\n",
    "              'max_iter': 500,\n",
    "              'random_state': 816\n",
    "              }\n",
    "    lrcv.set_params(**params)\n",
    "    lrcv.fit(X_train, y_train_cls)\n",
    "    return lrcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features files\n",
      "Ordinal encoding\n",
      "Features document-term matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 11.1min finished\n"
     ]
    }
   ],
   "source": [
    "clf = lr2cv(preprocess='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([[ 0.80731436,  0.80630129,  0.80549083],\n",
       "        [ 0.8123797 ,  0.81258231,  0.8138993 ],\n",
       "        [ 0.80488299,  0.80437646,  0.80397123],\n",
       "        [ 0.80042549,  0.80083072,  0.8005268 ],\n",
       "        [ 0.79134576,  0.79154844,  0.79185245]]),\n",
       " 1: array([[ 0.77175565,  0.77236349,  0.77155303],\n",
       "        [ 0.77236349,  0.77266741,  0.77226218],\n",
       "        [ 0.77135042,  0.77165434,  0.77226218],\n",
       "        [ 0.76932428,  0.76831121,  0.76780468],\n",
       "        [ 0.76520065,  0.76661938,  0.76793677]]),\n",
       " 2: array([[ 0.92827474,  0.92807213,  0.92807213],\n",
       "        [ 0.9306048 ,  0.93070611,  0.93070611],\n",
       "        [ 0.92989565,  0.93009827,  0.92999696],\n",
       "        [ 0.93080742,  0.93101003,  0.93070611],\n",
       "        [ 0.92764491,  0.92784759,  0.92754358]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dict with classes as the keys\n",
    "clf.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([ 0.80326966,  0.80312784,  0.80314812]),\n",
       " 1: array([ 0.7699989 ,  0.77032317,  0.77036377]),\n",
       " 2: array([ 0.92944551,  0.92954682,  0.92940498])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_scores = {}\n",
    "for i in clf.scores_.keys():\n",
    "    dic_scores[i] = np.mean(clf.scores_[i], axis=0)\n",
    "dic_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.1,   1. ,  10. ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.Cs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.1,  10. ,   1. ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 7,  8, 12],\n",
       "        [ 7, 10, 25],\n",
       "        [ 6,  9, 11],\n",
       "        [ 9,  8, 11],\n",
       "        [ 6,  7, 12]],\n",
       "\n",
       "       [[ 7, 10, 24],\n",
       "        [ 7,  9, 13],\n",
       "        [ 7,  8, 11],\n",
       "        [ 9, 30, 41],\n",
       "        [ 8, 20, 14]],\n",
       "\n",
       "       [[ 9, 12, 30],\n",
       "        [ 8, 16, 32],\n",
       "        [ 8, 10, 19],\n",
       "        [ 8, 12, 30],\n",
       "        [ 8, 10, 82]]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv training with another set of parameters: `solver=lbfgs` and `multi_class=multinomial`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lr2cv2(preprocess='linear'):\n",
    "    X_train, y_train_cls, X_test, _, _ = load_data()\n",
    "    if preprocess=='log':\n",
    "        X_train, X_test = _preprocess_log(X_train, X_test)\n",
    "    else:\n",
    "        X_train, X_test = _preprocess(X_train, X_test)\n",
    "\n",
    "    lrcv = LogisticRegressionCV()\n",
    "    params = {'Cs': [0.1, 1, 10],\n",
    "              'cv': 5,\n",
    "              'solver': 'lbfgs',\n",
    "              'n_jobs': -1,\n",
    "              'verbose': 1,\n",
    "              'max_iter': 10000,\n",
    "              'multi_class': 'multinomial',\n",
    "              'random_state': 816\n",
    "              }\n",
    "    lrcv.set_params(**params)\n",
    "    lrcv.fit(X_train, y_train_cls)\n",
    "    return lrcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features files\n",
      "Ordinal encoding\n",
      "Features document-term matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  3.7min finished\n"
     ]
    }
   ],
   "source": [
    "clf2 = lr2cv2(preprocess='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7497158 ,  0.74902691,  0.74894587])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(clf2.scores_[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.1,   1. ,  10. ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.Cs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 298,  655,  906],\n",
       "        [ 287,  647, 1189],\n",
       "        [ 294,  546, 1343],\n",
       "        [ 289,  616, 1195],\n",
       "        [ 304,  634, 1001]]], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation by hand, to get logloss estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(dtrain, dtest=None, solver='liblinear', multi_cls='ovr'):\n",
    "    clf = LogisticRegression()\n",
    "    params = {'C': 0.1,\n",
    "              'solver': solver,\n",
    "              'multi_class': multi_cls,\n",
    "              'n_jobs': -1,\n",
    "              'verbose': 1,\n",
    "              'max_iter': 10000,\n",
    "              'random_state': 36883\n",
    "              }\n",
    "    clf.set_params(**params)\n",
    "    if dtest:\n",
    "        clf.fit(dtrain[0], dtrain[1])\n",
    "        y_train_pred, y_test_pred = clf.predict_proba(dtrain[0]), clf.predict_proba(dtest[0])\n",
    "        y_train_loss, y_test_loss = log_loss(dtrain[1], y_train_pred), log_loss(dtest[1], y_test_pred)\n",
    "        return clf, y_train_loss, y_test_loss\n",
    "    else:\n",
    "        clf.fit(dtrain[0], dtrain[1])\n",
    "        y_train_pred = clf.predict_proba(dtrain[0])\n",
    "        y_train_loss = log_loss(dtrain[1], y_train_pred)\n",
    "        return clf, y_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_cv(preprocess='linear', solver='liblinear', multi_cls='ovr'):\n",
    "    X_train, y_train_cls, X_test, _, _ = load_data()\n",
    "    if preprocess == 'log':\n",
    "        X_train, X_test = _preprocess_log(X_train, X_test)\n",
    "    else:\n",
    "        X_train, X_test = _preprocess(X_train, X_test)\n",
    "\n",
    "    cv_scores, n_folds = [], 5\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=816)\n",
    "    for i, (train_ind, val_ind) in enumerate(skf.split(X_train, y_train_cls)):\n",
    "        print(\"Running Fold\", i + 1, \"/\", n_folds)\n",
    "        start = time.time()\n",
    "        \n",
    "        train_x, val_x = X_train.iloc[train_ind, :], X_train.iloc[val_ind, :]\n",
    "        train_y, val_y = y_train_cls.iloc[train_ind], y_train_cls.iloc[val_ind]\n",
    "        clf, train_loss, val_loss = run_model((train_x, train_y), (val_x, val_y), solver, multi_cls)\n",
    "        cv_scores.append([train_loss, val_loss])\n",
    "        \n",
    "        print(\"train_loss: {0:.6f}, val_loss: {1:.6f}\".format(train_loss, val_loss), end=\"\\t\")\n",
    "        \n",
    "        end = time.time()\n",
    "        m, s = divmod(end-start, 60)\n",
    "        h, m = divmod(m, 60)\n",
    "        print(\"time elapsed: %d:%02d:%02d\" % (h, m, s))\n",
    "        \n",
    "    mean_train_loss = np.mean([cv_scores[i][0] for i in range(len(cv_scores))])\n",
    "    mean_val_loss = np.mean([cv_scores[i][1] for i in range(len(cv_scores))])\n",
    "    print(\"train_loss mean: {0:.6f}, val_loss mean: {1:.6f}\".format(mean_train_loss, mean_val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try multi-class classification using one-vs-rest method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features files\n",
      "Ordinal encoding\n",
      "Features document-term matrix\n",
      "Running Fold 1 / 5\n",
      "[LibLinear]train_loss: 0.560027, val_loss: 0.577107\ttime elapsed: 0:00:17\n",
      "Running Fold 2 / 5\n",
      "[LibLinear]train_loss: 0.563201, val_loss: 0.562485\ttime elapsed: 0:00:18\n",
      "Running Fold 3 / 5\n",
      "[LibLinear]train_loss: 0.560879, val_loss: 0.571717\ttime elapsed: 0:00:17\n",
      "Running Fold 4 / 5\n",
      "[LibLinear]train_loss: 0.559111, val_loss: 0.573838\ttime elapsed: 0:00:17\n",
      "Running Fold 5 / 5\n",
      "[LibLinear]train_loss: 0.561189, val_loss: 0.567258\ttime elapsed: 0:00:17\n",
      "train_loss mean: 0.560882, val_loss mean: 0.570481\n"
     ]
    }
   ],
   "source": [
    "train_cv(preprocess='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using one-versus-rest for multi-class classification, with `sag`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features files\n",
      "Ordinal encoding\n",
      "Features document-term matrix\n",
      "Running Fold 1 / 5\n",
      "convergence after 1414 epochs took 112 seconds\n",
      "convergence after 1426 epochs took 113 seconds\n",
      "convergence after 3515 epochs took 266 seconds\n",
      "train_loss: 0.560049, val_loss: 0.577191\ttime elapsed: 0:04:26\n",
      "Running Fold 2 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 1323 epochs took 106 seconds\n",
      "convergence after 1751 epochs took 139 seconds\n",
      "convergence after 3194 epochs took 246 seconds\n",
      "train_loss: 0.563106, val_loss: 0.562527\ttime elapsed: 0:04:05\n",
      "Running Fold 3 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 1407 epochs took 124 seconds\n",
      "convergence after 1561 epochs took 125 seconds\n",
      "convergence after 3135 epochs took 258 seconds\n",
      "train_loss: 0.560876, val_loss: 0.572066\ttime elapsed: 0:04:18\n",
      "Running Fold 4 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 1386 epochs took 113 seconds\n",
      "convergence after 1420 epochs took 115 seconds\n",
      "convergence after 3632 epochs took 279 seconds\n",
      "train_loss: 0.559132, val_loss: 0.573781\ttime elapsed: 0:04:39\n",
      "Running Fold 5 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 1419 epochs took 113 seconds\n",
      "convergence after 1572 epochs took 125 seconds\n",
      "convergence after 3623 epochs took 276 seconds\n",
      "train_loss: 0.561150, val_loss: 0.567327\ttime elapsed: 0:04:36\n",
      "train_loss mean: 0.560863, val_loss mean: 0.570578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  4.6min finished\n"
     ]
    }
   ],
   "source": [
    "train_cv(preprocess='log', solver='sag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features files\n",
      "Ordinal encoding\n",
      "Features document-term matrix\n",
      "Running Fold 1 / 5\n",
      "convergence after 1401 epochs took 208 seconds\n",
      "train_loss: 0.553578, val_loss: 0.572902\ttime elapsed: 0:03:28\n",
      "Running Fold 2 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 2051 epochs took 307 seconds\n",
      "train_loss: 0.557061, val_loss: 0.556253\ttime elapsed: 0:05:06\n",
      "Running Fold 3 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 1473 epochs took 220 seconds\n",
      "train_loss: 0.554637, val_loss: 0.567690\ttime elapsed: 0:03:40\n",
      "Running Fold 4 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 1472 epochs took 221 seconds\n",
      "train_loss: 0.553010, val_loss: 0.569458\ttime elapsed: 0:03:41\n",
      "Running Fold 5 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 1518 epochs took 231 seconds\n",
      "train_loss: 0.555273, val_loss: 0.561092\ttime elapsed: 0:03:50\n",
      "train_loss mean: 0.554712, val_loss mean: 0.565479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  3.8min finished\n"
     ]
    }
   ],
   "source": [
    "train_cv(preprocess='log', solver='sag', multi_cls='multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features files\n",
      "Ordinal encoding\n",
      "Features document-term matrix\n",
      "Running Fold 1 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   11.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.553280, val_loss: 0.572040\ttime elapsed: 0:00:11\n",
      "Running Fold 2 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   11.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.556947, val_loss: 0.556453\ttime elapsed: 0:00:12\n",
      "Running Fold 3 / 5\n",
      "train_loss: 0.554349, val_loss: 0.567760\ttime elapsed: 0:00:12\n",
      "Running Fold 4 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   12.4s finished\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   12.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.552729, val_loss: 0.569465\ttime elapsed: 0:00:12\n",
      "Running Fold 5 / 5\n",
      "train_loss: 0.555045, val_loss: 0.561168\ttime elapsed: 0:00:16\n",
      "train_loss mean: 0.554470, val_loss mean: 0.565377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   16.3s finished\n"
     ]
    }
   ],
   "source": [
    "train_cv(preprocess='log', solver='lbfgs', multi_cls='multinomial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks using different solvers and multi_class methods leads to the same classification logloss. Even though the underlying principle between `ovr` and `multinomial` is quite different, prediction from `multinomial` class is only better than `ovr` by around 0.05. Different solvers do not affect final prediction that much."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
